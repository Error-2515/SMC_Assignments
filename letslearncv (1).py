# -*- coding: utf-8 -*-
"""letsLearnCV.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JO3YopVQ-7vCc_DbP9LczbOC-LTuPfGV

## **Where do i start w CV??**
if you ask this question to anyone they'll throw this roadmap at you.

1. **Understand the Basics of Python**: Python is the most commonly used programming language for CV. Familiarize yourself with basic syntax, data structures, and control flow.

2. **Learn NumPy and OpenCV**: NumPy is a fundamental library for numerical computing in Python, and OpenCV is a popular library for computer vision tasks. Learn how to manipulate arrays using NumPy and perform basic image processing operations using OpenCV.

3. **Study Image Processing Techniques**: Learn about different image processing techniques such as blurring, edge detection, thresholding, and morphological operations. Understanding these techniques will form the foundation of your CV knowledge.

4. **Explore Machine Learning**: Familiarize yourself with machine learning concepts such as classification, regression, and clustering. Understand how these techniques can be applied to solve CV problems, such as object detection and image segmentation.

5. **Dive into Deep Learning**: Deep learning has revolutionized CV in recent years. Study deep learning frameworks like TensorFlow or PyTorch and learn about convolutional neural networks (CNNs), which are particularly effective for CV tasks.

6. **Work on Projects**: Apply your knowledge by working on CV projects. Start with simple projects like image classification or face detection and gradually move on to more complex tasks like object tracking or image captioning.

7. **Stay Updated**: CV is a rapidly evolving field, so it's important to stay updated with the latest research and developments. Follow CV conferences, journals, and online communities to stay informed about new techniques and advancements.

8. **Practice, Practice, Practice**: Like any skill, proficiency in CV comes with practice. Keep experimenting with different techniques, algorithms, and datasets to deepen your understanding and improve your skills.

Remember, learning CV is a journey, so be patient and persistent. Good luck!

See even ChatGPT did throw this at me.

and how much time do u think looking at this will take you to learn CV?? days weeks or months??
"""



"""## what're we going to do today
We're going to do something different here today that'll help you get to know everything that is needed to know for a beginner in these few hours

1. the direction where to start working in
2. the domain knowlege
3. what suits you best in CV (research, dev, business)
4. the efforts u need to put in.

1. Direction:

*   The different directions one can take in computer vision, such as research, development, or business applications.


*   Let's see examples of each direction and highlight the opportunities and challenges associated with them.

*   Think about the interests and goals to determine which direction suits you best.

2. Domain Knowledge:

*   The foundational concepts of computer vision, including image processing techniques, machine learning algorithms, and deep learning architectures

*   Resources and recommendations for further learning in each area.

    1.   [Sentdex- YT](https://www.youtube.com/channel/UCfzlCWGWYyIQ0aLC5w48gBQ?reload=9)
    2.   [Introduction to Computer Vision and Image Processing](https://www.coursera.org/learn/introduction-computer-vision-watson-opencv)
    3.   [Advanced Computer Vision with TensorFlow](https://www.coursera.org/learn/advanced-computer-vision-with-tensorflow)
    4.   [Deep Learning Applications for Computer Vision](https://www.coursera.org/learn/deep-learning-computer-vision)


*   Understand the imp of domain knowledge before diving into practical applications.


3. and 4. are personal choices. and remember you're personal choices are the only ones that differentiate you and make you stand out.

##Lets start w what CV is?

Computer Vision (CV) is a field of artificial intelligence (AI) and computer science that focuses on enabling machines to interpret, analyze, and understand the visual world. It aims to replicate the human visual system's ability to perceive and comprehend visual information from digital images or videos.

**Key Components of Computer Vision:**

1. **Image Acquisition:** Computer vision systems acquire visual data from various sources, such as cameras, satellites, or medical imaging devices.

2. **Pre-processing:** Once images or videos are acquired, pre-processing techniques are applied to enhance the quality of the data and prepare it for further analysis. This may involve tasks like noise reduction, color correction, or resizing.

3. **Feature Extraction:** Computer vision algorithms extract meaningful features from the visual data to represent objects, shapes, textures, and patterns. Features can include edges, corners, color histograms, or more complex descriptors.

4. **Object Detection and Recognition:** Object detection involves locating and identifying objects within images or videos, while object recognition assigns semantic labels to detected objects. This enables systems to understand the content of visual data and recognize specific objects or categories.

5. **Image Classification:** Image classification assigns a label or category to an entire image based on its contents. This is often achieved using machine learning algorithms trained on labeled datasets.

6. **Segmentation:** Image segmentation divides an image into regions or segments based on shared characteristics, such as color, intensity, or texture. This is useful for tasks like scene understanding, medical image analysis, or autonomous navigation.

7. **Tracking and Motion Analysis:** Computer vision systems can track objects' movements over time and analyze motion patterns within videos. This is crucial for applications like surveillance, sports analytics, or robotics.

8. **Depth Estimation:** Depth estimation techniques infer the distance of objects from the camera, enabling systems to perceive the 3D structure of a scene. This is essential for tasks like augmented reality, autonomous driving, or robotics.


## Problem types in CV



## TOOO much theory lets get our hands dirty

Lets look at small code snippets thats help u understand how images are understood by a machine
"""

# wget -O image.jpg https://learnopencv.com/wp-content/uploads/2021/04/input-image-for-demo-throughout-1024x682.jpg

"""**1. Loading and Displaying an Image:**"""

import cv2
from google.colab.patches import cv2_imshow

# Load an image from file
image = cv2.imread('image.jpg')
# image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
# Display the image
cv2_imshow(image)

"""**2. Converting an Image to Grayscale:**"""

# Convert the image to grayscale
gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

# Display the grayscale image
cv2_imshow(gray_image)
#print(gray_image)

"""**3. Resize the image:**"""

resized_image = cv2.resize(image, (300, 200))

# Display the resized image
cv2_imshow(resized_image)

"""**4. Apply Gaussian Blur**"""

# Apply Gaussian blur to the image
blurred_image = cv2.GaussianBlur(image, (5, 5), 0)

# Display the blurred image
cv2_imshow(blurred_image)

"""* Gaussian blur is a common image processing technique used to reduce noise and smooth out details in an image. It involves convolving the image with a Gaussian kernel.
 * why use it?
   - because it helps in Noise Reduction,Detail Smoothing,Edge Preservation,Preprocessing for Further Analysis

**5. Drawing Shapes and Text on an Image:**
"""

# Draw a rectangle on the image
cv2.rectangle(image, (100, 100), (300, 200), (0, 255, 0), 2)

# Draw a circle on the image
cv2.circle(image, (200, 150), 50, (255, 0, 0), -1)

# Add text to the image
cv2.putText(image, 'Rectangle and Circle', (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)

# Display the image with shapes and text
cv2_imshow(image)

"""Now lets recap w a small quiz. dont tell the answers just read and raise hands. lets see who gets them more right.

1. **Question:** What is the purpose of converting an image to grayscale?
   - A) To increase the image resolution
   - B) To reduce the number of colors in the image
   - C) To enhance the contrast of the image
   - D) To apply blurring effect to the image

2. **Question:** Which image processing technique is commonly used for noise reduction?
   - A) Sobel edge detection
   - B) Histogram equalization
   - C) Gaussian blur
   - D) Canny edge detection

3. **Question:** What is the purpose of resizing an image?
   - A) To change the aspect ratio of the image
   - B) To increase the file size of the image
   - C) To adjust the dimensions of the image
   - D) To add borders to the image

4. **Question:** What is the primary purpose of blurring an image using Gaussian blur?
   - A) To sharpen the image details
   - B) To enhance the image contrast
   - C) To reduce image noise
   - D) To increase image brightness

5. **Question:** What is the purpose of converting an image from BGR to RGB color space in OpenCV?
   - A) To increase the image resolution
   - B) To reduce the file size of the image
   - C) To align with the color representation used by most visualization tools
   - D) To apply edge detection algorithms to the image

## Discussion
* Lets look at some REAL real-life projects in computer vision.
* And discuss the requirements and challenges of each project idea.

## Q&A (10 minutes)

## CV and Deep learning go hand in hand

We hear CNN a lot in CV, what's that??
* Convolutional Neural Networks (CNNs) are a class of deep neural networks that are particularly effective for image recognition and computer vision tasks. They are inspired by the structure and function of the visual cortex in the brain and consist of multiple layers, including convolutional layers, pooling layers, and fully connected layers. CNNs automatically learn features from input images through a process called convolution, enabling them to extract hierarchical representations of visual data.



so that looks like this..
"""

import tensorflow as tf

# Create a simple CNN model using TensorFlow
model = tf.keras.Sequential([
    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),
    tf.keras.layers.MaxPooling2D((2, 2)),
    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),
    tf.keras.layers.MaxPooling2D((2, 2)),
    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(10, activation='softmax')
])

# Compile the model
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

# Print model summary
model.summary()

"""Don't worry U dont need to understand it ALL. just look at it and get familiar so that when u look back you be like. "Ah this! chote rehne dekhton tha ye chillar cheezan haha.." Trust me it's no big deal.

## Now lets look at CUDA whats that and why this now..

lets answer why this now first.
* because the whole CV world is moving towards it. lemme correct that, not "moving" but "running" towards it

Why? because it drives you CV solutions!!

‍The CUDA (Compute Unified Device Architecture) platform is a software framework developed by NVIDIA to expand the capabilities of GPU acceleration. It allows developers to access the raw computing power of CUDA GPUs to process data faster than with traditional CPUs.


For more info u can read this blog:
https://blogs.nvidia.com/blog/what-is-cuda-2/

## Now lets build SOMETHING!!

Wer're going to build a region counting project using YOLO"""


# Clone Ultralytics repo
# git clone https://github.com/ultralytics/ultralytics

# %cd ultralytics/

# wget -O mall2way.mp4 "https://videos.pexels.com/video-files/4750076/4750076-hd_1920_1080_25fps.mp4"

# pip install ultralytics

from ultralytics import YOLO
from ultralytics.solutions import object_counter
import cv2

model = YOLO("yolov8n.pt")
cap = cv2.VideoCapture("mall2way.mp4")
assert cap.isOpened(), "Error reading video file"
w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))

# Define region points
region_points = [(20, 400), (1080, 404), (1080, 360), (20, 360)]
classes_to_count = [0, 2]
# Video writer
video_writer = cv2.VideoWriter("object_counting_output.avi",
                       cv2.VideoWriter_fourcc(*'mp4v'),
                       fps,
                       (w, h))

# Init Object Counter
counter = object_counter.ObjectCounter()
counter.set_args(view_img=False,
                 reg_pts=region_points,
                 classes_names=model.names,
                 draw_tracks=False,
                 line_thickness=2)

while cap.isOpened():
    success, im0 = cap.read()
    if not success:
        print("Video frame is empty or video processing has been successfully completed.")
        break
    tracks = model.track(im0, persist=False, show=False)

    im0 = counter.start_counting(im0, tracks)
    video_writer.write(im0)

cap.release()
video_writer.release()
cv2.destroyAllWindows()

# ffmpeg -i object_counting_output.avi output.mp4

from IPython.display import HTML
from base64 import b64encode
mp4 = open('object_counting_output.avi','rb').read()
data_url = "data:video/mp4;base64," + b64encode(mp4).decode()
HTML("""
<video width=400 controls>
      <source src="%s" type="video/mp4">
</video>
""" % data_url)

"""## Take home assignment
Congrats! You've built your own Obj detector and counter uisng CNN.
You can take this home and you're task is to push this to your github repo
"""

